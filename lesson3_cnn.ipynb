{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/3\n",
      "17462/17462 [==============================] - 42s 2ms/step - loss: 0.6739 - acc: 0.5817 - val_loss: 0.6730 - val_acc: 0.6177\n",
      "Epoch 2/3\n",
      "17462/17462 [==============================] - 40s 2ms/step - loss: 0.5938 - acc: 0.6861 - val_loss: 0.5592 - val_acc: 0.7123\n",
      "Epoch 3/3\n",
      "17462/17462 [==============================] - 40s 2ms/step - loss: 0.5178 - acc: 0.7428 - val_loss: 0.5404 - val_acc: 0.7316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fae8d73e128>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "# load our stored X, y\n",
    "pickle_in = open('/home/broaddaysk/Desktop/tinderbot/X.pickle', 'rb')\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open('/home/broaddaysk/Desktop/tinderbot/y.pickle', 'rb')\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0 # normalize (generally speaking, we would use tf.keras.utils.normalize())\n",
    "\n",
    "# use feedforward model\n",
    "model = Sequential()\n",
    "\n",
    "# first hidden layer (need to specify input_shape, which in this case is (IMG_SIZE, IMG_SIZE, 1). depth is 1)\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:])) # 256 output filters in conv, kernel size is 3x3\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # pool window is 2x2\n",
    "\n",
    "# second hidden layer\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# convert 3D feature maps to 1D feature vector\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1)) # 1 output node can output binary classification (activate/don't activate)\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# set training parameters\n",
    "model.compile(loss='binary_crossentropy', # categorical would also work\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# actually train model\n",
    "model.fit(X, y, batch_size=32, epochs=3, validation_split=0.3) # 32 samples per gradient update, 30% of training data used as validation data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
